{"meta":{"title":"Dreamilk","subtitle":"","description":"","author":"Dreamilk","url":"http://yoursite.com","root":"/"},"pages":[],"posts":[{"title":"gan代码参考","slug":"gan代码参考","date":"2020-06-10T01:59:45.000Z","updated":"2020-06-10T02:00:24.779Z","comments":true,"path":"2020/06/10/gan代码参考/","link":"","permalink":"http://yoursite.com/2020/06/10/gan%E4%BB%A3%E7%A0%81%E5%8F%82%E8%80%83/","excerpt":"","text":"https://github.com/dreamilk/PyTorch-GAN","categories":[],"tags":[]},{"title":"caffe安装 build_cmd方式","slug":"caffe安装 参考资料","date":"2020-06-05T13:52:17.000Z","updated":"2020-06-05T13:53:51.800Z","comments":true,"path":"2020/06/05/caffe安装 参考资料/","link":"","permalink":"http://yoursite.com/2020/06/05/caffe%E5%AE%89%E8%A3%85%20%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99/","excerpt":"","text":"https://blog.csdn.net/chris_zhangrx/article/details/79096015","categories":[],"tags":[]},{"title":"ssd目标检测算法精讲","slug":"ssd目标检测算法精讲","date":"2020-06-05T13:50:36.000Z","updated":"2020-06-05T13:51:41.347Z","comments":true,"path":"2020/06/05/ssd目标检测算法精讲/","link":"","permalink":"http://yoursite.com/2020/06/05/ssd%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E7%AE%97%E6%B3%95%E7%B2%BE%E8%AE%B2/","excerpt":"","text":"https://blog.csdn.net/qq_41368247/article/details/88027340","categories":[],"tags":[]},{"title":"下采样层与池化层","slug":"下采样层与池化层","date":"2020-06-04T11:42:03.000Z","updated":"2020-06-04T11:42:17.445Z","comments":true,"path":"2020/06/04/下采样层与池化层/","link":"","permalink":"http://yoursite.com/2020/06/04/%E4%B8%8B%E9%87%87%E6%A0%B7%E5%B1%82%E4%B8%8E%E6%B1%A0%E5%8C%96%E5%B1%82/","excerpt":"","text":"下采样层与池化层的关系及其作用它们的作用似乎没有差别，在这个方面来说池化层可以理解为下采样层，就是一个东西，两个名字而已。下面就他们在CNN中的位置、方法和作用作简要的说明。 位置池化或子采样层通常紧跟在CNN中的卷积层之后。 常用方法最大值池化（max-pooling）：对邻域内特征点取最大值。平均值池化（mean-pooling）：对邻域内特征点求平均。 作用降维，减少网络要学习的参数数量。防止过拟合。可以扩大感知野。可以实现不变性:平移不变性,旋转不变性,尺度不变性。","categories":[],"tags":[]},{"title":"caffe中 ReLu层与Sigmoid层 输入输出","slug":"caffe中-ReLu层与Sigmoid层-输入输出","date":"2020-06-04T08:41:24.000Z","updated":"2020-06-04T08:45:44.698Z","comments":true,"path":"2020/06/04/caffe中-ReLu层与Sigmoid层-输入输出/","link":"","permalink":"http://yoursite.com/2020/06/04/caffe%E4%B8%AD-ReLu%E5%B1%82%E4%B8%8ESigmoid%E5%B1%82-%E8%BE%93%E5%85%A5%E8%BE%93%E5%87%BA/","excerpt":"","text":"caffe中的relu层与sigmoid层relu层的输入输出一般可以相同，这是因为relu支持in-replace操作，可以节省内存sigmoid层输入输出层 不能相同在caffe中 输出层top一般为 本层的name","categories":[],"tags":[]}],"categories":[],"tags":[]}